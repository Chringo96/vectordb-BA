{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3a999f-a6f1-424f-be11-6813dab58570",
   "metadata": {},
   "source": [
    "## Qdrant how to get started properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d47da1-9072-47f2-9a3d-857eb40d0c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11bac3b4-38c2-455f-8bfc-16a2e7f66cbf",
   "metadata": {},
   "source": [
    "### In Developement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ce897-be81-4022-819b-c751b9a707b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10315ab6-9c25-47f5-9876-9115435c5fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ac5d84f-f864-4c48-b879-3da4a01925d4",
   "metadata": {},
   "source": [
    "### In Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721937d7-6c24-4e7d-b127-5a4dda250925",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8752d82-b764-4046-a5f7-14872096f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dd23d70-445b-4d04-b1b9-e4598f3215aa",
   "metadata": {},
   "source": [
    "### Multitenancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed39e7-d123-4cc5-8b3a-7d6a54d5a91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f504b-86c3-48e4-b282-36c7926493b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a1fa64-d773-43ea-999c-d3569cdcf889",
   "metadata": {},
   "source": [
    "### Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bf323-bf67-4f65-ab9f-c9c5d64cf627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752a275-4f5d-46c9-be03-f3598d7e3395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fb71822-f3e2-4969-b96f-c82370541e2e",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0690d310-c186-4d7a-a0b8-76e77cb212de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-tools 1.64.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: C:\\Users\\Chringo\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f87c1db-678f-4b1a-af03-c052f30c0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDSbwWIkrfmk4sBmudBe95OwF4rbF_xOO4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7206c47-0fc1-472b-a59f-7b05ade3bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0739833-ce9b-4cb2-8a8f-8496f0806a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the astronaut break up with his girlfriend before going to Mars?\n",
      "\n",
      "Because he needed space!\n"
     ]
    }
   ],
   "source": [
    "# LangChain supports many other chat models. Here, we're using Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# supports many more optional parameters. Hover on your `ChatOllama(...)`\n",
    "# class to view the latest available supported parameters\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "\n",
    "# using LangChain Expressive Language chain syntax\n",
    "# learn more about the LCEL on\n",
    "# /docs/concepts/#langchain-expression-language-lcel\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# for brevity, response is printed in terminal\n",
    "# You can use LangServe to deploy your application for\n",
    "# production\n",
    "print(chain.invoke({\"topic\": \"Space travel\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
